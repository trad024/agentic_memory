{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trad024/agentic_memory/blob/main/agentic_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QAZagHO_BSTT",
        "outputId": "eae06bff-7a21-43fa-c84d-a213b17e836d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.62 (from langchain-google-genai)\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m763.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-core-0.3.63 langchain-google-genai-2.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4f01c6b3726f4442ad645a62b67c6d5b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr7mEAzzDWuN"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_c7RppQD9PY",
        "outputId": "574cbaae-01de-4003-9d7f-a112e15bf12c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API Key configured.\n",
            "ChatGoogleGenerativeAI model initialized.\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = gemini_api_key\n",
        "    genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "    print(\"Gemini API Key configured.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error configuring Gemini API Key: {e}\")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "print(\"ChatGoogleGenerativeAI model initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZJcsCAEhD9SZ",
        "outputId": "9708933a-a02a-4ebf-a55b-667cfe1d7446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name: models/embedding-gecko-001, Supported methods: ['embedText', 'countTextTokens']\n",
            "Model name: models/gemini-1.0-pro-vision-latest, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-pro-vision, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-pro-latest, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-pro-001, Supported methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Model name: models/gemini-1.5-pro-002, Supported methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Model name: models/gemini-1.5-pro, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-latest, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-001, Supported methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Model name: models/gemini-1.5-flash-001-tuning, Supported methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
            "Model name: models/gemini-1.5-flash, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-002, Supported methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "Model name: models/gemini-1.5-flash-8b, Supported methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-8b-001, Supported methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-8b-latest, Supported methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-8b-exp-0827, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-1.5-flash-8b-exp-0924, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-2.5-pro-exp-03-25, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-pro-preview-03-25, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-preview-04-17, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-preview-05-20, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-preview-04-17-thinking, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-pro-preview-05-06, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-exp, Supported methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Model name: models/gemini-2.0-flash, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-001, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-exp-image-generation, Supported methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-lite-001, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-lite, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-preview-image-generation, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemini-2.0-flash-lite-preview-02-05, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-lite-preview, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-pro-exp, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-pro-exp-02-05, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-exp-1206, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-thinking-exp-01-21, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-thinking-exp, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-thinking-exp-1219, Supported methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-preview-tts, Supported methods: ['countTokens', 'generateContent']\n",
            "Model name: models/gemini-2.5-pro-preview-tts, Supported methods: ['countTokens', 'generateContent']\n",
            "Model name: models/learnlm-2.0-flash-experimental, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemma-3-1b-it, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemma-3-4b-it, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemma-3-12b-it, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemma-3-27b-it, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/gemma-3n-e4b-it, Supported methods: ['generateContent', 'countTokens']\n",
            "Model name: models/embedding-001, Supported methods: ['embedContent']\n",
            "Model name: models/text-embedding-004, Supported methods: ['embedContent']\n",
            "Model name: models/gemini-embedding-exp-03-07, Supported methods: ['embedContent', 'countTextTokens']\n",
            "Model name: models/gemini-embedding-exp, Supported methods: ['embedContent', 'countTextTokens']\n",
            "Model name: models/aqa, Supported methods: ['generateAnswer']\n",
            "Model name: models/imagen-3.0-generate-002, Supported methods: ['predict']\n",
            "Model name: models/veo-2.0-generate-001, Supported methods: ['predictLongRunning']\n",
            "Model name: models/gemini-2.5-flash-preview-native-audio-dialog, Supported methods: ['countTokens', 'bidiGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3, Supported methods: ['countTokens', 'bidiGenerateContent']\n",
            "Model name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog, Supported methods: ['countTokens', 'bidiGenerateContent']\n",
            "Model name: models/gemini-2.0-flash-live-001, Supported methods: ['bidiGenerateContent', 'countTokens']\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# List available models and their supported methods\n",
        "models = genai.list_models()\n",
        "for model in models:\n",
        "    print(f\"Model name: {model.name}, Supported methods: {model.supported_generation_methods}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGJiFqXRD9VH"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(temperature=0.7, model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLJCqIDPD9Xv",
        "outputId": "9f9dee93-e0fb-4482-d882-41b61cc5d5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "User: hello\n",
            "\n",
            "AI Message:  Hello there!\n",
            "\n",
            "User: what's my name?\n",
            "\n",
            "AI Message:  I do not know your name.\n",
            "\n",
            "User: my name is moataz\n",
            "\n",
            "AI Message:  It's nice to meet you, Moataz.\n",
            "\n",
            "User: what's my favorite sport?\n",
            "\n",
            "AI Message:  I don't know your favorite sport.\n",
            "\n",
            "User: what's my name?\n",
            "\n",
            "AI Message:  Your name is Moataz.\n",
            "\n",
            "User: my favorite sport is running\n",
            "\n",
            "AI Message:  Okay, Moataz, your favorite sport is running.\n",
            "\n",
            "User: exit\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Define System Prompt\n",
        "system_prompt = SystemMessage(\"You are a helpful AI Assistant. Answer the User's queries succinctly in one sentence.\")\n",
        "\n",
        "# Start Storage for Historical Message History\n",
        "messages = [system_prompt]\n",
        "\n",
        "while True:\n",
        "\n",
        "    # Get User's Message\n",
        "    user_message = HumanMessage(input(\"\\nUser: \"))\n",
        "\n",
        "    if user_message.content.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        # Extend Messages List With User Message\n",
        "        messages.append(user_message)\n",
        "\n",
        "    # Pass Entire Message Sequence to LLM to Generate Response\n",
        "    response = llm.invoke(messages)\n",
        "\n",
        "    print(\"\\nAI Message: \", response.content)\n",
        "\n",
        "    # Add AI's Response to Message List\n",
        "    messages.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abAme7PXD9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db74b7d-1b06-429c-bfbf-be794e2bfd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Message 1 - SYSTEM:  You are a helpful AI Assistant. Answer the User's queries succinctly in one sentence.\n",
            "\n",
            "Message 2 - HUMAN:  hello\n",
            "\n",
            "Message 3 - AI:  Hello there!\n",
            "\n",
            "Message 4 - HUMAN:  what's my name?\n",
            "\n",
            "Message 5 - AI:  I do not know your name.\n",
            "\n",
            "Message 6 - HUMAN:  my name is moataz\n",
            "\n",
            "Message 7 - AI:  It's nice to meet you, Moataz.\n",
            "\n",
            "Message 8 - HUMAN:  what's my favorite sport?\n",
            "\n",
            "Message 9 - AI:  I don't know your favorite sport.\n",
            "\n",
            "Message 10 - HUMAN:  what's my name?\n",
            "\n",
            "Message 11 - AI:  Your name is Moataz.\n",
            "\n",
            "Message 12 - HUMAN:  my favorite sport is running\n",
            "\n",
            "Message 13 - AI:  Okay, Moataz, your favorite sport is running.\n"
          ]
        }
      ],
      "source": [
        "# Looking into our Memory\n",
        "\n",
        "for i in range(len(messages)):\n",
        "    print(f\"\\nMessage {i+1} - {messages[i].type.upper()}: \", messages[i].content)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKdRK-Zd0Yp-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw9UjXVrhTd0LYJ3a1ggac",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}